# XDR-Net: Explainable Hybrid CNNâ†’Token-Attention for Diabetic Retinopathy Detection

**One-line:** A lightweight, explainable DR grader that couples an EfficientNet backbone with a single self-attention bridge, delivering strong performance and clear Grad-CAM evidence on APTOS 2019.

---

##  Overview

Automated diabetic retinopathy (DR) screening demands models that are **accurate, efficient, and transparent**. Pure CNNs capture local lesion cues (microaneurysms, hemorrhages, exudates) but can miss **global retinal context**; attention models capture global relations but are often heavy. **XDR-Net** balances both: it keeps EfficientNetâ€™s compact convolutional features and adds a single token-level self-attention block before pooling. We pair this with a pragmatic training recipe for imbalanced grades and clinician-oriented visual explanations.

---

## Preprocessing (APTOS 2019)

We apply a reproducible, screening-oriented preprocessing pipeline:

- Circular crop of the fundus and background removal  
- Resize to **384Ã—384**, per-channel standardization  
- **CLAHE** on luminance to enhance local lesion contrast while limiting noise

**CLAHE example**

![CLAHE](https://github.com/ItsCodeBakery/XDR-NET/blob/main/Proposed%20Methodology/plots/ClahePrep.png)

---

## ğŸ—Proposed Methodology (XDR-Net)

**Backbone:** EfficientNet (from `timm`) for compact, high-quality feature extraction  
**Token-Attention bridge:** a **single Multi-Head Self-Attention (MHA)** applied on the final feature map (tokenized) to inject **global retinal context** with minimal overhead  
**Head:** Global Average Pooling â†’ LayerNorm â†’ Dropout â†’ Linear (320â†’5) for 5-class DR grading  
**Training/Inference:** AdamW (cosine schedule), class-weighted CE with label smoothing; test-time augmentation and temperature scaling for calibrated probabilities  
**Explainability:** Grad-CAM on the last conv block; class-wise grids and error panels

**Architecture sketch**

![Methodology](https://github.com/ItsCodeBakery/XDR-NET/blob/main/Proposed%20Methodology/plots/METHODLOGY.png)

---

## Results (APTOS 2019)

**Validation split:** 1,805 images (five classes)

- **XDR-Net:** **Accuracy 97.40%**, **Macro-F1 97.38%**  
- **Baselines (same pipeline):**
  - ResNet-18 â€” Acc **81.82%**, Macro-F1 **68.39%**
  - ResNet-50 â€” Acc **82.73%**, Macro-F1 **70.32%**
  - ConvNeXt-Base â€” Acc **81.04%**, Macro-F1 **66.18%**

**Confusion matrix (counts + normalized)**

![Confusion Matrix](https://github.com/ItsCodeBakery/XDR-NET/blob/main/Proposed%20Methodology/plots/confusion_matrix_counts_vs_normalized.png)

---

## Explainability

We generate class-discriminative **Grad-CAM** overlays from the final convolutional block, enabling graders to visualize lesion evidence and failure modes.

**Class-wise Grad-CAM montage**

![Grad-CAM](https://github.com/ItsCodeBakery/XDR-NET/blob/main/Proposed%20Methodology/plots/xdrGradCam.png)

---

##  Repository Layout
Proposed Methodology/
â”œâ”€ code/ # XDR-Net training/inference scripts or notebooks
â”œâ”€ plots/ # training curves, CM, Grad-CAM, methodology figure, CLAHE demo
â””â”€ splits/ # train/val CSVs used in APTOS experiments
BaseLineExperement/
â”œâ”€ resnet18/
â”‚ â”œâ”€ code/ # training/inference for ResNet-18
â”‚ â””â”€ plots/ # curves, confusion matrix, etc.
â”œâ”€ resnet50/
â”‚ â”œâ”€ code/
â”‚ â””â”€ plots/
â””â”€ conveynet/
â”œâ”€ code/
â””â”€ plots/


> Note: GitHub hides empty foldersâ€”each subfolder includes a small placeholder to remain visible.

---

## ğŸ” Reproducibility (Kaggle / Local)

- **Dataset:** APTOS 2019 (add on Kaggle and point `train_images/` + `train.csv`)  
- **Env:** Python 3.10+, PyTorch 2.x, `timm`, `torchvision`, `scikit-learn`, `pandas`, `matplotlib`  
- **Run:** See `Proposed Methodology/code/` for XDR-Net and `BaseLineExperement/*/code/` for baselines  
- **Explainability:** Grad-CAM scripts reproduce the class-wise grids shown above

---

## ğŸ“« Contact

Questions or collaboration: **shayan.ali@imsciences.edu.pk**


